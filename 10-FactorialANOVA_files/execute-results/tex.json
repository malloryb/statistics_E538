{
  "hash": "06314b696142d443f036747f8b3a8f32",
  "result": {
    "markdown": "---\nauthor: \n  - Mallory L. Barnes\naliases: [factorial-anova.html]\nabstract-title: Chapter notes\nabstract: Portions adapted from the Factorial ANOVA chapter, contributors Keryn Bain, Rachel Blakey, Stephanie Brodie, Corey Callaghan, Will Cornwell, Kingsley Griffin, Matt Holland, James Lavender, Andrew Letten, Shinichi Nakagawa, Shaun Nielsen, Alistair Poore, Gordana Popovic, Fiona Robinson and Jakub Stoklosa. \"Environmental Computing\" <https://environmentalcomputing.net/>\n---\n\n\n\n\n\n# Factorial ANOVA\n\n\n\n::: {.cell hash='cache/unnamed-chunk-2_a3a75fd303cedd2d48d21c72cd5d2da0'}\n\n:::\n\n\n\nFactorial designs may be the most complicated topic discussed in this class. What's so complicated? Up until now we have been talking about experiments with two important bits: the independent variable (the manipulation) and the dependent variable (what we measure). In most cases, our independent variable has had two levels, or three or four; but, there has only been one independent variable.\n\nWhat if you wanted to manipulate more than one independent variable? If you did that you would have at least two independent variables, each with their own levels. The rest of the book is about factorial designs with more than one independent variable, and the statistical tests we use to analyze those designs.\n\nLet's go through some examples of designs. We will be imagining experiments that are trying to improve students grades. So, the dependent variable will always be grade on a test.\n\n1.  1 IV (two levels)\n\nWe would use a t-test for these designs, because they only have two levels.\n\na.  Time of day (Morning versus Afternoon): Do students do better on tests when they take them in the morning versus the afternoon? There is one IV (time of day), with two levels (Morning vs. Afternoon)\n\nb.  Caffeine (some caffeine vs no caffeine): Do students do better on tests when they drink caffeine versus not drinking caffeine? There is one IV (caffeine), with two levels (some caffeine vs no caffeine)\n\n<!-- -->\n\n2.  1 IV (three levels):\n\nWe would use an ANOVA for these designs because they have more than two levels\n\na.  Time of day (Morning, Afternoon, Night): Do students do better on tests when they take them in the morning, the afternoon, or at night? There is one IV (time of day), with three levels (Morning, Afternoon, and Night)\n\nb.  Caffeine (1 coffee, 2 coffees, 3 coffees): Do students do better on tests when they drink 1 coffee, 2 coffees, or three coffees? There is one IV (caffeine), with three levels (1 coffee, 2 coffees, and 3 coffees)\n\n<!-- -->\n\n3.  **2 IVs: IV1 (two levels), IV2 (two levels)**\n\nWe haven't talked about what kind of test to run for this design (hint: it is called a factorial ANOVA)\n\na.  IV1 (Time of Day: Morning vs. Afternoon); IV2 (Caffeine: some caffeine vs. no caffeine): How does time of day and caffeine consumption influence student grades? We had students take tests in the morning or in the afternoon, with or without caffeine. There are two IVs (time of day & caffeine). IV1 (Time of day) has two levels (morning vs afternoon). IV2 (caffeine) has two levels (some caffeine vs. no caffeine)\n\nOK, let's stop here for the moment. The first two designs both had one IV. The third design shows an example of a design with 2 IVs (time of day and caffeine), each with two levels. This is called a **2x2 Factorial Design**. It is called a **factorial** design, because the levels of each independent variable are fully crossed. This means that first each level of one IV, the levels of the other IV are also manipulated. \"HOLD ON STOP PLEASE!\" Yes, it seems as if we are starting to talk in the foreign language of statistics and research designs. We apologize for that. We'll keep mixing it up with some plain language, and some pictures.\n\n## Factorial basics\n\n### 2x2 Designs\n\nWe've just started talking about a **2x2 Factorial design**. We said this means the IVs are crossed. To illustrate this, take a look at @fig-10designs. We show an abstract version and a concrete version using time of day and caffeine as the two IVs, each with two levels in the design:\n\n\n\n::: {.cell hash='cache/fig-10designs_a88963bb6f142cbbfdb71b2db37a3398'}\n::: {.cell-output-display}\n![Structure of 2x2 factorial designs](imgs/figures/2x2Design.png){#fig-10designs width=75%}\n:::\n:::\n\n\n\nLet's talk about this crossing business. Here's what it means for the design. For the first level of Time of Day (morning), we measure test performance when some people drank caffeine and some did not. So, in the morning we manipulate whether or not caffeine is taken. Also, in the second level of the Time of Day (afternoon), we also manipulate caffeine. Some people drink or don't drink caffeine in the afternoon as well, and we collect measures of test performance in both conditions.\n\nWe could say the same thing, but talk from the point of view of the second IV. For example, when people drink caffeine, we test those people in the morning, and in the afternoon. So, time of day is manipulated for the people who drank caffeine. Also, when people do not drink caffeine, we test those people in the morning, and in the afternoon, So, time of day is manipulated for the people who did not drink caffeine.\n\nFinally, each of the four squares representing a DV, is called a **condition**. So, we have 2 IVs, each with 2 levels, for a total of 4 conditions. This is why we call it a 2x2 design. 2x2 = 4. The notation tells us how to calculate the total number of conditions.\n\n### Factorial Notation\n\nAnytime **all of the levels** of each IV in a design are fully crossed, so that they all occur for each level of every other IV, we can say the design is a **fully factorial** design.\n\nWe use a notation system to refer to these designs. The rules for notation are as follows. Each IV get's it's own number. The number of levels in the IV is the number we use for the IV. Let's look at some examples:\n\n2x2 = There are two IVS, the first IV has two levels, the second IV has 2 levels. There are a total of 4 conditions, 2x2 = 4.\n\n2x3 = There are two IVs, the first IV has two levels, the second IV has three levels. There are a total of 6 conditions, 2x3 = 6\n\n3x2 = There are two IVs, the first IV has three levels, the second IV has two levels. There are a total of 6 conditions, 3x2=6.\n\n4x4 = There are two IVs, the first IV has 4 levels, the second IV has 4 levels. There are a total of 16 condition, 4x4=16\n\n2x3x2 = There are a total of three IVs. The first IV has 2 levels. The second IV has 3 levels. The third IV has 2 levels. There are a total of 12 condition. 2x3x2 = 12.\n\n### 2 x 3 designs\n\n@fig-1023design shows the structure of a 2x3 factorial design.\n\n\n\n::: {.cell hash='cache/fig-1023design_7585b5c47ca27b299f75e0e58e169045'}\n::: {.cell-output-display}\n![Structure of 2x3 factorial designs](imgs/figures/2x3Design.png){#fig-1023design width=75%}\n:::\n:::\n\n\n\nAll we did was add another row for the second IV. It's a 2x3 design, so it should have 6 conditions. As you can see there are now 6 cells to measure the DV.\n\n## Purpose of Factorial Designs\n\nFactorial designs let researchers manipulate more than one thing at once. This immediately makes things more complicated, because as you will see, there are many more details to keep track of. Why would researchers want to make things more complicated? Why would they want to manipulate more than one IV at a time?\n\nBefore we go on, let's clarify what we mean by manipulating more than one thing at once. When you have one IV in your design, by definition, you are manipulating only **one** thing. This might seem confusing at first, because the IV has more than one level, so it seems to have more than one manipulation. Consider manipulating the number of coffees that people drink before they do a test. We could have one IV (coffee), with three levels (1, 2, or 3 coffees). You might want to say we have three manipulations here, drinking 1, 2, or 3 coffees. But, the way we define manipulation is terms of the IV. There is only one coffee IV. It does have three levels. Nevertheless, we say you are only doing one coffee manipulation. The only thing you are manipulating is the amount of coffee. That's just one thing, so it's called one manipulation. To do another, second manipulation, you need to additionally manipulate something that is not coffee (like time of day in our previous example).\n\nReturning to our question: why would researchers want to manipulate more than one thing in their experiment. The answer might be kind of obvious. They want to know if more than one thing causes change in the thing they are measuring!\n\n### Factorials manipulate an effect of interest\n\nFactorial designs enable researchers to sift through multiple layers of influence to grasp the broader picture. Complicated? Certainly, but it’s complexity that mirrors the real world where multiple factors often come into play simultaneously.\n\nLet's make sense of this by contemplating a multifaceted environmental study. Imagine we're environmental scientists, eager to measure the effects of various pollutants on aquatic life. Here's what we could do:\n\n1. **Choose a bioindicator**: Our subjects are the varied aquatic macroinvertebrates, whose species diversity is a critical measure of water health—our dependent variable.\n   \n2. **Identify impactful variables**:  We've identified the usual suspect – excess Nutrient-loaded agricultural runoff (Pollutant A), notorious for depleting oxygen and threatening our aquatic buddies. We’ll add this to our macroinvertebrates' environment and observe the ripple effects on their diversity, using a pristine control (No Pollutant) for comparison.\n\n3. **Measure the impact**: We'll examine the richness and variety of macroinvertebrate species when exposed to each type of pollutant.\n\n4. **Detect the variation**: Variations in macroinvertebrate diversity will illuminate the 'Pollution effect'. The impact of pollutaiton on macroinvertebrate diversity. \n\nThe proof is in the visuals.We aim to contrast macroinvertebrate diversity in the shadow of Pollutant A with a pollutant-free scenario. @fig-10biodiversityeffect shows how the data might look.\n\n\n\n::: {.cell fig.asp='0.5' hash='cache/fig-10biodiversityeffect_235516b6b0af287eb66030d61ca70b49'}\n::: {.cell-output-display}\n![Example data illustrating the influence of different pollution types on aquatic macroinvertebrate species diversity](10-FactorialANOVA_files/figure-pdf/fig-10biodiversityeffect-1.pdf){#fig-10biodiversityeffect width=100%}\n:::\n:::\n\n\n\nBehold! The macroinvertebrate lineup takes a hit from both pollutants, but they really don't like the industrial waste after-party. In general, it is very common to use the word **effect** to refer to the differences caused by the manipulation. This is what we could call the \"Pollution effect\".\n\n### Manipulating the Polltuion effect\n\nThis is where factorial designs come in to play. We've already pinpointed a 'Pollution effect'—the change in macroinvertebrate biodiversity when pollutants enter their habitat. This effect serves as our guide, leading us to ask: Where does pollution strike the hardest? What conditions exacerbate its harmful impact?\n\nOne possible lever for controlling this Pollution effect could be the timing of fertilizer application, reducing runoff by strategic scheduling post-rainfall. Cover cropping might also act as a shield, protecting our waters from nutrient excess. But now, we introduce a new player: flow rate. Will high flow rate reduce impacts of pollution, since the pollution will scoot on out of there?  Or, paradoxically, could it exacerbate the issue, hastening the spread of pollutants that might otherwise degrade if left undisturbed? \n\nOur question evolves: Does flow rate influence the Pollution Effect? We postulate that a higher flow rate might reduce the observable Pollution Effect compared to a more stagnant, low flow environment. If our theory holds water, the results could flow out like the data in @fig-10flow.\n\n\n\n::: {.cell fig.asp='0.5' hash='cache/fig-10flow_e0be10e2cf3669053dcc119deef2b22d'}\n::: {.cell-output-display}\n![Example data showing how the Pollution effect could be modulated by a Flow manipulation. Pollution plotted on the x-axis, makes it more difficult to compare the changes in the pollution effect between flow rate conditions](10-FactorialANOVA_files/figure-pdf/fig-10flow-1.pdf){#fig-10flow width=100%}\n:::\n:::\n\n\n\nIn this graph, we maintain consistency by placing the Pollution conditions on the x-axis.The bars represent the average macroinvertebrate diversity for each combination of flow and pollution conditions, with colors distinguishing the flow rates. But, it's not as helpful as it could be. We can try to interpret this graph, but @fig-10flowB plots the same data in a way that makes it easier to see what we are talking about.\n\n\n\n::: {.cell fig.asp='0.5' hash='cache/fig-10FlowB_6e733f241de9a23905e1f2182b5c487c'}\n::: {.cell-output-display}\n![Example data showing how the pollution effect could be modulated by a flow rate manipulation. Flow condition plotted on the x-axis, makes it easier to compare the changes in the pollution effect between Flow conditions](10-FactorialANOVA_files/figure-pdf/fig-10FlowB-1.pdf){#fig-10FlowB width=100%}\n:::\n:::\n\n\n\nHere, the x-axis represents the Flow Rate, with the color of the bars indicating the Pollution condition. This graph layout simplifies the comparison of the Pollution effect within each Flow Rate condition, making it easier to discern the interaction between these two factors.\n\n**No-Flow condition**: In the low flow condition, our macroinvertebrates were observed in both polluted and unpolluted waters. This mirrors the baseline scenario of our study. Consistently with our predictions, the graph would likely show a significant difference: a higher species count in unpolluted waters compared to polluted ones. Thus, we'd observe a Pollution effect, with a specific difference in species count illustrating the impact of pollution under low flow conditions.\n\n**Flow condition**: In the high flow condition, the macroinvertebrates also faced both polluted and unpolluted environments. However, the dynamic nature of high flow was hypothesized to influence their response to pollution. The expectation was that the swift current might diminish the observable Pollution effect by dispersing pollutants more effectively. If the graph supports our hypothesis, we'd see a smaller difference in species count between the polluted and unpolluted conditions under high flow, indicating a lessened Pollution effect.\n\nShould our research validate these predictions, we could infer that flow rate does indeed modulate the Pollution effect. In a low flow environment, the Pollution effect might be pronounced, as observed by the larger difference in species counts. Conversely, in a high flow scenario, the effect diminishes, with the difference in biodiversity less stark. Therefore, the manipulation of flow rate could potentially alter the Pollution effect by a quantifiable margin, underscored by the variation in species counts between the two flow conditions.v\n\nThis is our description of why factorial designs are so useful. They allow researchers to find out what kinds of manipulations can cause changes in the effects they measure. In our environmental study, for instance, we've measured the Pollution effect on macroinvertebrate biodiversity. Then, we introduced the variable of flow rate to see if and how it might alter this effect. If our goal is to untangle the web of ecological dynamics, we'd need to delve into the mechanisms by which flow rate could influence pollutant dispersion and, subsequently, biodiversity. We have the initial evidence suggesting that flow rate can indeed sway the Pollution effect. The next step is to craft hypotheses on the nature of this influence—perhaps proposing that faster flows dilute pollutants more effectively, thus mitigating their negative impact on biodiversity. These hypotheses then become the basis for further experiments, designed to test their validity and expand our understanding of these complex environmental interactions.\n\n## Graphing the means\n\nIn our example above we showed you two bar graphs of the very same means for our 2x2 design. Even though the graphs plot identical means, they look different, so they are more or less easy to interpret by looking at them. Results from 2x2 designs are also often plotted with line graphs. Those look different too. There are four different graphs in @fig-10visualdiffs, using bars and lines to plot the very same means from before. We are showing you this so that you realize **how you graph your data matters** because it makes it more or less easy for people to understand the results. Also, how the data is plotted matters for what you need to look at to interpret the results.\n\n\n\n::: {.cell hash='cache/fig-10visualdiffs_73bd55fd6ba058fd9fbb19eb4282ff3e'}\n::: {.cell-output-display}\n![same example means plotted using bar graphs or line graphs, and with Pollution or Flow on the x-axis](10-FactorialANOVA_files/figure-pdf/fig-10visualdiffs-1.pdf){#fig-10visualdiffs width=100%}\n:::\n:::\n\n\n\n## Knowing what you want to find out\n\nWhen you conduct a design with more than one IV, you get more means to look at. As a result, there are more kinds of questions that you can ask of the data. Sometimes it turns out that the questions that you can ask, are not the ones that you want to ask, or have an interest in asking. Because you ran the design with more than one IV, you have the opportunity to ask these kinds of extra questions.\n\nWhat kinds of extra questions? Let's keep going with our Pollution effect experiment. We have the first IV where we manipulated Pollution. So, we could find the overall means in spot-the difference for the Pollution vs. no-Pollution conditions (that's two means). The second IV was Flow. We could find the overall means in spot-the-difference performance for the Flow vs. no-Flow conditions (that's two more means). We could do what we already did, and look at the means for each combination, that is the mean for Pollution/Flow, Pollution/no-Flow, no-Pollution/Flow, and no-Pollution/no-Flow (that's four more means, if you're counting).\n\nThere's even more. We could look at the mean Pollution effect (the difference between pollution and no pollution) for the low flow condition, and the mean Pollution effect for the high flow condition (that's two more).\n\n@fig-10alleffects shows multiple ways of looking at the means across four panels.\n\n\n\n::: {.cell hash='cache/fig-10alleffects_c7980f58e57ae8acee7fc0b562d4c961'}\n::: {.cell-output-display}\n![Each panel shows the mean for different effects in the design](10-FactorialANOVA_files/figure-pdf/fig-10alleffects-1.pdf){#fig-10alleffects width=100%}\n:::\n:::\n\n\n\nThe purpose of showing all of these means is to orient you to your problem. If you conduct a 2x2 design (and this is the most simple factorial that you can conduct), you will get all of these means. You need to know what you want to know from the means. That is, you need to be able to connect the research question to the specific means you are interested in analyzing.\n\nFor example, in our example, the research question was whether Flow would change the size of the Pollution effect. The top left panel gives us some info about this question. We can see all of the condition means, and we can visually see that the Pollution effect was larger in the No-Flow compared to the Flow condition. But, to \"see\" this, we need to do some visual subtraction. You need to look at the difference between the red and aqua bars for each of the High flow and Low flow conditions.\n\nDoes the top right panel tell us about whether Flow changed the size of the Pollution effect? NO, it just shows that there was an overall Pollution effect (this is called the **main effect** of Pollution). **Main effects** are any differences between the levels of one independent variable.\n\nDoes the bottom left panel tell us about whether Flow changed the size of the Pollution effect? NO! it just shows that there was an overall Flow effect, called the main effect of Flow. There was a stronger effect of pollution in the high flow condition, but this doesn't tell us if they were more negatively impacted in terms of species.\n\nFinally, how about the bottom left panel. Does this tell us about whether the Flow changed the size of the Pollution effect? YES! Notice, the y-axis is different for this panel. The y-axis here is labelled \"Pollution Effect\". You are looking at two difference scores. The Pollution effect in the no-Flow condition (10-5 = 5), and the Pollution effect in the Flow condition (11-9 = 2). These two bars are different as a function of Flow. So, it looks like Flow did produce a difference between the Pollution effects! This was the whole point of the fake study. It is these means that were most important for answering the question of the study. As a very last point, this panel contains what we call an **interaction**. We explain this in the next section.\n\n::: callout-tip\n## Pro tip\n\nMake sure you know what you want to know from your means before you run the study, otherwise you will just have way too many means, and you won't know what they mean.\n:::\n\n## Simple analysis of 2x2 repeated measures design\n\nNormally in a chapter about factorial designs we would introduce you to Factorial ANOVAs, which are totally a thing. We will introduce you to them soon. But, before we do that, we are going to show you how to analyze a 2x2 repeated measures ANOVA design with paired-samples t-tests. This is probably something you won't do very often. However, it turns out the answers you get from this method are the same ones you would get from an ANOVA.\n\nAdmittedly, if you found the explanation of ANOVA complicated, it will just appear even more complicated for factorial designs. So, our purpose here is to delay the complication, and show you with t-tests what it is that the Factorial ANOVA is doing. More important, when you do the analysis with t-tests, you have to be very careful to make all of the comparisons in the right way. As a result, you will get some experience learning how to know what it is you want to know from factorial designs. Once you know what you want to know, you can use the ANOVA to find out the answers, and then you will also know what answers to look for after you run the ANOVA. Isn't new knowledge fun!\n\nThe first thing we need to do is define **main effects** and **interactions**. Whenever you conduct a Factorial design, you will also have the opportunity to analyze **main effects** and **interactions**. However, the number of **main effects** and **interactions** you get to analyse depends on the number of IVs in the design.\n\n### Main effects\n\nFormally, main effects are the mean differences for a single Independent variable. There is always one main effect for each IV. A 2x2 design has 2 IVs, so there are two main effects. In our example, there is one main effect for Pollution, and one main effect for Flow. We will often ask if the main effect of some IV is significant. This refers to a statistical question: Were the differences between the means for that IV likely or unlikely to be caused by chance (sampling error).\n\nIf you had a 2x2x2 design, you would measure three main effects, one for each IV. If you had a 3x3x3 design, you would still only have 3 IVs, so you would have three main effects.\n\n### Interaction\n\nWe find that the interaction concept is one of the most confusing concepts for factorial designs. Formally, we might say an interaction occurs whenever the effect of one IV has an influence on the size of the effect for another IV. That's probably not very helpful. In more concrete terms, using our example, we found that the Flow IV had an effect on the size of the Pollution effect. The Pollution effect was larger when there was no-Flow, and it was smaller when there was a Flow. So, there was an interaction.\n\nWe might also say an interaction occurs when the difference between the differences are different! Yikes. Let's explain. There was a difference in spot-the-difference performance between the Pollution and no-Pollution condition, this is called the Pollution effect (it is a difference measure). The Flow manipulation changed the size of the Pollution effect, that means there was difference in the size of the Pollution effect. The Pollution effect is itself a measure of differences. So, we did find that the difference (in the Pollution effect) between the differences (the two measures of the Pollution effect between the Flow conditions) were different. When you start to write down explanations of what interactions are, you find out why they come across as complicated. We'll leave our definition of interaction like this for now. Don't worry, we'll go through lots of examples to help firm up this concept for you.\n\nThe number of interactions in the design also depend on the number of IVs. For a 2x2 design there is only 1 interaction. The interaction between IV1 and IV2. This occurs when the effect of say IV2 (whether there is a difference between the levels of IV2) changes across the levels of IV1. We could write this in reverse, and ask if the effect of IV1 (whether there is a difference between the levels of IV1) changes across the levels of IV2. However, just because we can write this two ways, does not mean there are two interactions. We'll see in a bit, that no matter how do the calculation to see if the difference scores--measure of effect for one IV-- change across the levels of the other IV, we always get the same answer. That is why there is only one interaction for a 2x2. Similarly, there is only one interaction for a 3x3, because there again we only have two IVs (each with three levels). Only when we get up to designs with more than 2 IVs, do we find more possible interactions. A design with three IVS, has four interactions. If the IVs are labelled A, B, and C, then we have three 2-way interactions (AB, AC, and BC), and one three-way interaction (ABC). We hold off on this stuff for much later\n\n### Looking at the data\n\nIt is most helpful to see some data in order to understand how we will analyze it. Let's imagine we ran our fake attention study. We will have five people in the study, and they will participate in all conditions, so it will be a fully repeated-measures design. The data could look like this:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-10_0770c3449452a0886a83d0fd2886f5fd'}\n::: {.cell-output-display}\n\\begin{tabular}{r|r|r|r|r}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c}{High Flow} \\\\\n\\cline{2-3} \\cline{4-5}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c}{Pollution} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5}\nsubject & A & B & C & D\\\\\n\\hline\n1 & 10 & 5 & 12 & 9\\\\\n\\hline\n2 & 8 & 4 & 13 & 8\\\\\n\\hline\n3 & 11 & 3 & 14 & 10\\\\\n\\hline\n4 & 9 & 4 & 11 & 11\\\\\n\\hline\n5 & 10 & 2 & 13 & 12\\\\\n\\hline\n\\multicolumn{5}{l}{\\rule{0pt}{1em}\\textit{Note: }}\\\\\n\\multicolumn{5}{l}{\\rule{0pt}{1em}Number of differences spotted for each subject in each condition. }\\\\\n\\end{tabular}\n:::\n:::\n\n\n\n### Main effect of Pollution\n\nThe main effect of Pollution compares the overall means for all scores in the no-Pollution and Pollution conditions, collapsing over the Flow conditions.\n\nThe yellow columns show the no-Pollution scores for each subject. The blue columns show the Pollution scores for each subject.\n\nThe overall means for for each subject, for the two Pollution conditions are shown to the right. For example, subject 1 had a 10 and 12 in the no-Pollution condition, so their mean is 11.\n\nWe are interested in the main effect of Pollution. This is the difference between the AC column (average of subject scores in the no-Pollution condition) and the BD column (average of the subject scores in the Pollution condition). These differences for each subject are shown in the last green column. The overall means, averaging over subjects are in the bottom green row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-11_636b1b9fd5fec1dd02166df90fa13823'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|>{}l|>{}l|>{}l|>{}l|l|l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{ All Conditions} & \\multicolumn{3}{c}{ } \\\\\n\\cline{2-5}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{ Pollution Means } & \\multicolumn{1}{c}{Pollution Effect } \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-8}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c}{Difference} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8}\nsubject & A & B & C & D & AC & BD & AC.minus.BD\\\\\n\\hline\n1 & \\cellcolor{yellow}{10} & \\cellcolor{lightgray}{5} & \\cellcolor{yellow}{12} & \\cellcolor{lightgray}{9} & 11 & 7 & \\cellcolor{lightgray}{4}\\\\\n\\hline\n2 & \\cellcolor{yellow}{8} & \\cellcolor{lightgray}{4} & \\cellcolor{yellow}{13} & \\cellcolor{lightgray}{8} & 10.5 & 6 & \\cellcolor{lightgray}{4.5}\\\\\n\\hline\n3 & \\cellcolor{yellow}{11} & \\cellcolor{lightgray}{3} & \\cellcolor{yellow}{14} & \\cellcolor{lightgray}{10} & 12.5 & 6.5 & \\cellcolor{lightgray}{6}\\\\\n\\hline\n4 & \\cellcolor{yellow}{9} & \\cellcolor{lightgray}{4} & \\cellcolor{yellow}{11} & \\cellcolor{lightgray}{11} & 10 & 7.5 & \\cellcolor{lightgray}{2.5}\\\\\n\\hline\n5 & \\cellcolor{yellow}{10} & \\cellcolor{lightgray}{2} & \\cellcolor{yellow}{13} & \\cellcolor{lightgray}{12} & 11.5 & 7 & \\cellcolor{lightgray}{4.5}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{11.1} & \\cellcolor{lightgray}{6.8} & \\cellcolor{lightgray}{4.3}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\nJust looking at the means, we can see there was a main effect of Pollution, the mean for the no-Pollution condition was 11.1, and the mean for the Pollution condition was 6.8. The size of the main effect was 4.3 (the difference between 11.1 and 6.8).\n\nNow, what if we wanted to know if this main effect of Pollution (the difference of 4.3) could have been caused by chance, or sampling error. You could do two things. You could run a paired samples $t$-test between the mean no-Pollution scores for each subject (column AC) and the mean Pollution scores for each subject (column BD). Or, you could run a one-sample $t$-test on the difference scores column, testing against a mean difference of 0. Either way you will get the same answer.\n\nHere's the paired samples version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-12_51bba9c98bd721d6b8feed2bb9e7cd76'}\n\n```\n#> \n#> \tPaired t-test\n#> \n#> data:  AC and BD\n#> t = 7.6615, df = 4, p-value = 0.00156\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  2.741724 5.858276\n#> sample estimates:\n#> mean difference \n#>             4.3\n```\n:::\n\n\n\nHere's the one sample version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-13_260d2e5fdf343dac9c91ff36c4fe4f56'}\n\n```\n#> \n#> \tOne Sample t-test\n#> \n#> data:  AC - BD\n#> t = 7.6615, df = 4, p-value = 0.00156\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  2.741724 5.858276\n#> sample estimates:\n#> mean of x \n#>       4.3\n```\n:::\n\n\n\nIf we were to write-up our results for the main effect of Pollution we could say something like this:\n\nThe main effect of Pollution was significant, $t$(4) = 7.66, $p$ = 0.001. The mean number of differences spotted was higher in the no-Pollution condition (M = 11.1) than the Pollution condition (M = 6.8).\n\n### Main effect of Flow\n\nThe main effect of Flow compares the overall means for all scores in the no-Flow and Flow conditions, collapsing over the Flow conditions.\n\nThe yellow columns show the no-Flow scores for each subject. The blue columns show the Flow scores for each subject.\n\nThe overall means for for each subject, for the two Flow conditions are shown to the right. For example, subject 1 had a 10 and 5 in the no-Flow condition, so their mean is 7.5.\n\nWe are interested in the main effect of Flow. This is the difference between the AB column (average of subject scores in the no-Flow condition) and the CD column (average of the subject scores in the Flow condition). These differences for each subject are shown in the last green column. The overall means, averaging over subjects are in the bottom green row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-14_d0e66ee21c260bfb4fb38a5e3f2e6b4b'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|>{}l|>{}l|>{}l|>{}l|l|l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{ All Conditions} & \\multicolumn{3}{c}{ } \\\\\n\\cline{2-5}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{ Flow Means } & \\multicolumn{1}{c}{Flow Effect } \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-8}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{Low Flow} & \\multicolumn{1}{c|}{High Flow} & \\multicolumn{1}{c}{Difference} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8}\nsubject & A & B & C & D & AB & CD & CD.minus.AB\\\\\n\\hline\n1 & \\cellcolor{yellow}{10} & \\cellcolor{yellow}{5} & \\cellcolor{lightgray}{12} & \\cellcolor{lightgray}{9} & 7.5 & 10.5 & \\cellcolor{lightgray}{3}\\\\\n\\hline\n2 & \\cellcolor{yellow}{8} & \\cellcolor{yellow}{4} & \\cellcolor{lightgray}{13} & \\cellcolor{lightgray}{8} & 6 & 10.5 & \\cellcolor{lightgray}{4.5}\\\\\n\\hline\n3 & \\cellcolor{yellow}{11} & \\cellcolor{yellow}{3} & \\cellcolor{lightgray}{14} & \\cellcolor{lightgray}{10} & 7 & 12 & \\cellcolor{lightgray}{5}\\\\\n\\hline\n4 & \\cellcolor{yellow}{9} & \\cellcolor{yellow}{4} & \\cellcolor{lightgray}{11} & \\cellcolor{lightgray}{11} & 6.5 & 11 & \\cellcolor{lightgray}{4.5}\\\\\n\\hline\n5 & \\cellcolor{yellow}{10} & \\cellcolor{yellow}{2} & \\cellcolor{lightgray}{13} & \\cellcolor{lightgray}{12} & 6 & 12.5 & \\cellcolor{lightgray}{6.5}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{6.6} & \\cellcolor{lightgray}{11.3} & \\cellcolor{lightgray}{4.7}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\nJust looking at the means, we can see there was a main effect of Flow. The mean number of differences spotted was 11.3 in the Flow condition, and 6.6 in the no-Flow condition. So, the size of the main effect of Flow was 4.7.\n\nIs a difference of this size likely o unlikely due to chance? We could conduct a paired-samples $t$-test on the AB vs. CD means, or a one-sample $t$-test on the difference scores. They both give the same answer:\n\nHere's the paired samples version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-15_6b34eca4f3f754b49db91bd03d5bc9fd'}\n\n```\n#> \n#> \tPaired t-test\n#> \n#> data:  CD and AB\n#> t = 8.3742, df = 4, p-value = 0.001112\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  3.141724 6.258276\n#> sample estimates:\n#> mean difference \n#>             4.7\n```\n:::\n\n\n\nHere's the one sample version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-16_8462fc487f3504de9c4ae07a43e0aa0e'}\n\n```\n#> \n#> \tOne Sample t-test\n#> \n#> data:  CD - AB\n#> t = 8.3742, df = 4, p-value = 0.001112\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  3.141724 6.258276\n#> sample estimates:\n#> mean of x \n#>       4.7\n```\n:::\n\n\n\nIf we were to write-up our results for the main effect of Flow we could say something like this:\n\nThe main effect of Flow was significant, t(4) = 8.37, p = 0.001. The mean number of differences spotted was higher in the Flow condition (M = 11.3) than the no-Flow condition (M = 6.6).\n\n### Interaction between Pollution and Flow\n\nNow we are ready to look at the interaction. Remember, the whole point of this fake study was what? Can you remember?\n\nHere's a reminder. We wanted to know if giving Flows versus not would change the size of the Pollution effect.\n\nNotice, neither the main effect of Pollution, or the main effect of Flow, which we just went through the process of computing, answers this question.\n\nIn order to answer the question we need to do two things. First, compute Pollution effect for each subject when they were in the no-Flow condition. Second, compute the Pollution effect for each subject when they were in the Flow condition.\n\nThen, we can compare the two Pollution effects and see if they are different. The comparison between the two Pollution effects is what we call the **interaction effect**. Remember, this is a difference between two difference scores. We first get the difference scores for the Pollution effects in the no-Flow and Flow conditions. Then we find the difference scores between the two Pollution effects. This difference of differences is the interaction effect (green column in the table)\n\n\n\n::: {.cell hash='cache/unnamed-chunk-17_2c8815a58b273dc12602ad1ead752e87'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|>{}l|>{}l|>{}l|>{}l|l|l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{ All Conditions} & \\multicolumn{3}{c}{ } \\\\\n\\cline{2-5}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{ Pollution Effects } & \\multicolumn{1}{c}{Interaction Effect } \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-8}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{Low Flow} & \\multicolumn{1}{c|}{High Flow} & \\multicolumn{1}{c}{Difference} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8}\nsubject & A & B & C & D & A-B & C-D & (A-B)-(C-D)\\\\\n\\hline\n1 & \\cellcolor{yellow}{10} & \\cellcolor{lightgray}{5} & \\cellcolor{yellow}{12} & \\cellcolor{lightgray}{9} & 5 & 3 & \\cellcolor{lightgray}{2}\\\\\n\\hline\n2 & \\cellcolor{yellow}{8} & \\cellcolor{lightgray}{4} & \\cellcolor{yellow}{13} & \\cellcolor{lightgray}{8} & 4 & 5 & \\cellcolor{lightgray}{-1}\\\\\n\\hline\n3 & \\cellcolor{yellow}{11} & \\cellcolor{lightgray}{3} & \\cellcolor{yellow}{14} & \\cellcolor{lightgray}{10} & 8 & 4 & \\cellcolor{lightgray}{4}\\\\\n\\hline\n4 & \\cellcolor{yellow}{9} & \\cellcolor{lightgray}{4} & \\cellcolor{yellow}{11} & \\cellcolor{lightgray}{11} & 5 & 0 & \\cellcolor{lightgray}{5}\\\\\n\\hline\n5 & \\cellcolor{yellow}{10} & \\cellcolor{lightgray}{2} & \\cellcolor{yellow}{13} & \\cellcolor{lightgray}{12} & 8 & 1 & \\cellcolor{lightgray}{7}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{6} & \\cellcolor{lightgray}{2.6} & \\cellcolor{lightgray}{3.4}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\nThe mean Pollution effects in the no-Flow (6) and Flow (2.6) conditions were different. This difference is the interaction effect. The size of the interaction effect was 3.4.\n\nHow can we test whether the interaction effect was likely or unlikely due to chance? We could run another paired-sample $t$-test between the two Pollution effect measures for each subject, or a one sample $t$-test on the green column (representing the difference between the differences). Both of these $t$-tests will give the same results:\n\nHere's the paired samples version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-18_209df2d879c6f10c7a127244b4231737'}\n\n```\n#> \n#> \tPaired t-test\n#> \n#> data:  A_B and C_D\n#> t = 2.493, df = 4, p-value = 0.06727\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.3865663  7.1865663\n#> sample estimates:\n#> mean difference \n#>             3.4\n```\n:::\n\n\n\nHere's the one sample version:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-19_71a011a86b61f62acc1a082459ca1137'}\n\n```\n#> \n#> \tOne Sample t-test\n#> \n#> data:  A_B - C_D\n#> t = 2.493, df = 4, p-value = 0.06727\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.3865663  7.1865663\n#> sample estimates:\n#> mean of x \n#>       3.4\n```\n:::\n\n\n\nOh look, the interaction was not significant. At least, if we had set our alpha criterion to 0.05, it would not have met that criteria. We could write up the results like this. The two-way interaction between between Pollution and Flow was not significant, $t$(4) = 2.493, $p$ = 0.067.\n\nOften times when a result is \"not significant\" according to the alpha criteria, the pattern among the means is not described further. One reason for this practice is that the researcher is treating the means as if they are not different (because there was an above alpha probability that the observed differences were due to chance). If they are not different, then there is no pattern to report.\n\nThere are differences in opinion among reasonable and expert statisticians on what should or should not be reported. Let's say we wanted to report the observed mean differences, we would write something like this:\n\nThe two-way interaction between between Pollution and Flow was not significant, t(4) = 2.493, p = 0.067. The mean Pollution effect in the no-Flow condition was 6 and the mean Pollution effect in the Flow condition was 2.6.\n\n### Writing it all up\n\nWe have completed an analysis of a 2x2 repeated measures design using paired-samples $t$-tests. Here is what a full write-up of the results could look like.\n\nThe main effect of Pollution was significant, $t$(4) = 7.66, $p$ = 0.001. The mean number of differences spotted was higher in the no-Pollution condition (M = 11.1) than the Pollution condition (M = 6.8).\n\nThe main effect of Flow was significant, $t$(4) = 8.37, $p$ = 0.001. The mean number of differences spotted was higher in the Flow condition (M = 11.3) than the no-Flow condition (M = 6.6).\n\nThe two-way interaction between between Pollution and Flow was not significant, $t$(4) = 2.493, $p$ = 0.067. The mean Pollution effect in the no-Flow condition was 6 and the mean Pollution effect in the Flow condition was 2.6.\n\n**Interim Summary**. We went through this exercise to show you how to break up the data into individual comparisons of interest. Generally speaking, a 2x2 repeated measures design would not be analyzed with three paired-samples $t$-test. This is because it is more convenient to use the repeated measures ANOVA for this task. We will do this in a moment to show you that they give the same results. And, by the same results, what we will show is that the $p$-values for each main effect, and the interaction, are the same. The ANOVA will give us $F$-values rather than $t$ values. It turns out that in this situation, the $F$-values are related to the $t$ values. In fact, $t^2 = F$.\n\n### 2x2 Repeated Measures ANOVA\n\nWe just showed how a 2x2 repeated measures design can be analyzed using paired-sampled $t$-tests. We broke up the analysis into three parts. The main effect for Pollution, the main effect for Flow, and the 2-way interaction between Pollution and Flow. We claimed the results of the paired-samples $t$-test analysis would mirror what we would find if we conducted the analysis using an ANOVA. Let's show that the results are the same. Here are the results from the 2x2 repeated-measures ANOVA, using the `aov` function in R.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-20_a83e4e2da0a86c14d907622cdf68c7af'}\n::: {.cell-output-display}\n\\begin{tabular}{l|r|r|r|r|r}\n\\hline\n  & Df & Sum Sq & Mean Sq & F value & Pr(>F)\\\\\n\\hline\nResiduals & 4 & 3.70 & 0.925 & NA & NA\\\\\n\\hline\nPollution & 1 & 92.45 & 92.450 & 58.698413 & 0.0015600\\\\\n\\hline\nResiduals1 & 4 & 6.30 & 1.575 & NA & NA\\\\\n\\hline\nFlow & 1 & 110.45 & 110.450 & 70.126984 & 0.0011122\\\\\n\\hline\nResiduals2 & 4 & 6.30 & 1.575 & NA & NA\\\\\n\\hline\nPollution:Flow & 1 & 14.45 & 14.450 & 6.215054 & 0.0672681\\\\\n\\hline\nResiduals & 4 & 9.30 & 2.325 & NA & NA\\\\\n\\hline\n\\end{tabular}\n:::\n:::\n\n\n\nLet's compare these results with the paired-samples $t$-tests.\n\n**Main effect of Pollution**: Using the paired samples $t$-test, we found $t$(4) =7.6615, $p$=0.00156. Using the ANOVA we found, $F$(1,4) = 58.69, $p$=0.00156. See, the $p$-values are the same, and $t^2 = 7.6615^2 = 58.69 = F$.\n\n**Main effect of Flow**: Using the paired samples $t$-test, we found $t$(4) =8.3742, $p$=0.001112. Using the ANOVA we found, $F$(1,4) = 70.126, $p$=0.001112. See, the $p$-values are the same, and $t^2 = 8.3742^2 = 70.12 = F$.\n\n**Interaction effect**: Using the paired samples $t$-test, we found $t$(4) =2.493, $p$=0.06727. Using the ANOVA we found, $F$(1,4) = 6.215, $p$=0.06727. See, the $p$-values are the same, and $t^2 = 2.493^2 = 6.215 = F$.\n\nThere you have it. The results from a 2x2 repeated measures ANOVA are the same as you would get if you used paired-samples $t$-tests for the main effects and interactions.\n\n## 2x2 Between-subjects ANOVA\n\nYou must be wondering how to calculate a 2x2 ANOVA. We haven't discussed this yet. We've only shown you that you don't have to do it when the design is a 2x2 repeated measures design (note this is a special case).\n\nWe are now going to work through some examples of calculating the ANOVA table for 2x2 designs. We will start with the between-subjects ANOVA for 2x2 designs. We do essentially the same thing that we did before (in the other ANOVAs), and the only new thing is to show how to compute the interaction effect.\n\nRemember the logic of the ANOVA is to partition the variance into different parts. The SS formula for the between-subjects 2x2 ANOVA looks like this:\n\n$SS_\\text{Total} = SS_\\text{Effect IV1} + SS_\\text{Effect IV2} + SS_\\text{Effect IV1xIV2} + SS_\\text{Error}$\n\nIn the following sections we use tables to show the calculation of each SS. We use the same example as before with the exception that **we are turning this into a between-subjects design**. There are now 5 different subjects in each condition, for a total of 20 subjects. As a result, we remove the subjects column.\n\n### SS Total\n\nWe calculate the grand mean (mean of all of the score). Then, we calculate the differences between each score and the grand mean. We square the difference scores, and sum them up. That is $SS_\\text{Total}$, reported in the bottom yellow row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-21_b50d2f355dc204091e673e1c3ba7e351'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|l|l|l|l|l|l|l|l|>{}l|>{}l|>{}l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{All Conditions} & \\multicolumn{4}{c|}{Difference from Grand Mean} & \\multicolumn{4}{c}{Squared Differences} \\\\\n\\cline{2-5} \\cline{6-9} \\cline{10-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c}{High Flow} \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-9} \\cline{10-11} \\cline{12-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c}{Pollution} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8} \\cline{9-9} \\cline{10-10} \\cline{11-11} \\cline{12-12} \\cline{13-13}\n  & A & B & C & D & A-GrandM & B-GrandM & C-GrandM & D-GrandM & (A-GrandM)\\textasciicircum{}2 & (B-GrandM)\\textasciicircum{}2 & (C-GrandM)\\textasciicircum{}2 & (D-GrandM)\\textasciicircum{}2\\\\\n\\hline\n & 10 & 5 & 12 & 9 & 1.05 & -3.95 & 3.05 & 0.05 & \\cellcolor{yellow}{1.1025} & \\cellcolor{yellow}{15.6025} & \\cellcolor{yellow}{9.3025} & \\cellcolor{yellow}{0.0025}\\\\\n\\hline\n & 8 & 4 & 13 & 8 & -0.95 & -4.95 & 4.05 & -0.95 & \\cellcolor{yellow}{0.9025} & \\cellcolor{yellow}{24.5025} & \\cellcolor{yellow}{16.4025} & \\cellcolor{yellow}{0.9025}\\\\\n\\hline\n & 11 & 3 & 14 & 10 & 2.05 & -5.95 & 5.05 & 1.05 & \\cellcolor{yellow}{4.2025} & \\cellcolor{yellow}{35.4025} & \\cellcolor{yellow}{25.5025} & \\cellcolor{yellow}{1.1025}\\\\\n\\hline\n & 9 & 4 & 11 & 11 & 0.05 & -4.95 & 2.05 & 2.05 & \\cellcolor{yellow}{0.0025} & \\cellcolor{yellow}{24.5025} & \\cellcolor{yellow}{4.2025} & \\cellcolor{yellow}{4.2025}\\\\\n\\hline\n & 10 & 2 & 13 & 12 & 1.05 & -6.95 & 4.05 & 3.05 & \\cellcolor{yellow}{1.1025} & \\cellcolor{yellow}{48.3025} & \\cellcolor{yellow}{16.4025} & \\cellcolor{yellow}{9.3025}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{9.6} & \\cellcolor{lightgray}{3.6} & \\cellcolor{lightgray}{12.6} & \\cellcolor{lightgray}{10} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{lightgray}{Grand Mean} & \\cellcolor{lightgray}{8.95} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{yellow}{sums} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{Sums} & \\cellcolor{yellow}{7.3125} & \\cellcolor{yellow}{148.3125} & \\cellcolor{yellow}{71.8125} & \\cellcolor{yellow}{15.5125}\\\\\n\\hline\n\\cellcolor{yellow}{SS Total} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{SS Total} & \\cellcolor{yellow}{242.95} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\n### SS Pollution\n\nWe need to compute the SS for the main effect for Pollution. We calculate the grand mean (mean of all of the scores). Then, we calculate the means for the two Pollution conditions. Then we treat each score as if it was the mean for it's respective Pollution condition. We find the differences between each Pollution condition mean and the grand mean. Then we square the differences and sum them up. That is $SS_\\text{Pollution}$, reported in the bottom yellow row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-22_e4db859518a7348064ea61150b7fc9a4'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|l|l|l|l|l|l|l|l|>{}l|>{}l|>{}l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{All Conditions} & \\multicolumn{4}{c|}{Pollution Mean - GM} & \\multicolumn{4}{c}{Squared Differences} \\\\\n\\cline{2-5} \\cline{6-9} \\cline{10-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c}{High Flow} \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-9} \\cline{10-11} \\cline{12-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c}{Pollution} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8} \\cline{9-9} \\cline{10-10} \\cline{11-11} \\cline{12-12} \\cline{13-13}\n  & A & B & C & D & NDM-GM A & DM-GM B & NDM-GM C & DM-GM D & (NDM-GM )\\textasciicircum{}2 A & (DM-GM)\\textasciicircum{}2 B & (NDM-GM)\\textasciicircum{}2 C & (DM-GM)\\textasciicircum{}2 D\\\\\n\\hline\n & 10 & 5 & 12 & 9 & 2.15 & -2.15 & 2.15 & -2.15 & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225}\\\\\n\\hline\n & 8 & 4 & 13 & 8 & 2.15 & -2.15 & 2.15 & -2.15 & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225}\\\\\n\\hline\n & 11 & 3 & 14 & 10 & 2.15 & -2.15 & 2.15 & -2.15 & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225}\\\\\n\\hline\n & 9 & 4 & 11 & 11 & 2.15 & -2.15 & 2.15 & -2.15 & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225}\\\\\n\\hline\n & 10 & 2 & 13 & 12 & 2.15 & -2.15 & 2.15 & -2.15 & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225} & \\cellcolor{yellow}{4.6225}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{9.6} & \\cellcolor{lightgray}{3.6} & \\cellcolor{lightgray}{12.6} & \\cellcolor{lightgray}{10} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{lightgray}{Grand Mean} & \\cellcolor{lightgray}{8.95} & \\cellcolor{lightgray}{No Pollution} & \\cellcolor{lightgray}{11.1} & \\cellcolor{lightgray}{Pollution} & \\cellcolor{lightgray}{6.8} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{yellow}{sums} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{Sums} & \\cellcolor{yellow}{23.1125} & \\cellcolor{yellow}{23.1125} & \\cellcolor{yellow}{23.1125} & \\cellcolor{yellow}{23.1125}\\\\\n\\hline\n\\cellcolor{yellow}{SS Pollution} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{SS Pollution} & \\cellcolor{yellow}{92.45} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\nThese tables are a lot to look at! Notice here, that we first found the grand mean (8.95). Then we found the mean for all the scores in the no-Pollution condition (columns A and C), that was 11.1. All of the difference scores for the no-Pollution condition are 11.1-8.95 = 2.15. We also found the mean for the scores in the Pollution condition (columns B and D), that was 6.8. So, all of the difference scores are 6.8-8.95 = -2.15. Remember, means are the balancing point in the data, this is why the difference scores are +2.15 and -2.15. The grand mean 8.95 is in between the two condition means (11.1 and 6.8), by a difference of 2.15.\n\n### SS Flow\n\nWe need to compute the SS for the main effect for Flow. We calculate the grand mean (mean of all of the scores). Then, we calculate the means for the two Flow conditions. Then we treat each score as if it was the mean for it's respective Flow condition. We find the differences between each Flow condition mean and the grand mean. Then we square the differences and sum them up. That is $SS_\\text{Flow}$, reported in the bottom yellow row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-23_29dc86283eee827381da275cdc752925'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|l|l|l|l|l|l|l|l|>{}l|>{}l|>{}l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{All Conditions} & \\multicolumn{4}{c|}{Flow Mean - GM} & \\multicolumn{4}{c}{Squared Differences} \\\\\n\\cline{2-5} \\cline{6-9} \\cline{10-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c}{High Flow} \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-9} \\cline{10-11} \\cline{12-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c}{Pollution} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8} \\cline{9-9} \\cline{10-10} \\cline{11-11} \\cline{12-12} \\cline{13-13}\n  & A & B & C & D & NRM-GM A & NRM-GM B & RM-GM C & RM-GM D & (NRM-GM )\\textasciicircum{}2 A & (NRM-GM)\\textasciicircum{}2 B & (RM-GM)\\textasciicircum{}2 C & (RM-GM)\\textasciicircum{}2 D\\\\\n\\hline\n & 10 & 5 & 12 & 9 & -2.35 & -2.35 & 2.35 & 2.35 & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225}\\\\\n\\hline\n & 8 & 4 & 13 & 8 & -2.35 & -2.35 & 2.35 & 2.35 & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225}\\\\\n\\hline\n & 11 & 3 & 14 & 10 & -2.35 & -2.35 & 2.35 & 2.35 & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225}\\\\\n\\hline\n & 9 & 4 & 11 & 11 & -2.35 & -2.35 & 2.35 & 2.35 & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225}\\\\\n\\hline\n & 10 & 2 & 13 & 12 & -2.35 & -2.35 & 2.35 & 2.35 & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225} & \\cellcolor{yellow}{5.5225}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{9.6} & \\cellcolor{lightgray}{3.6} & \\cellcolor{lightgray}{12.6} & \\cellcolor{lightgray}{10} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{lightgray}{Grand Mean} & \\cellcolor{lightgray}{8.95} & \\cellcolor{lightgray}{Low Flow} & \\cellcolor{lightgray}{6.6} & \\cellcolor{lightgray}{High Flow} & \\cellcolor{lightgray}{11.3} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{yellow}{sums} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{Sums} & \\cellcolor{yellow}{27.6125} & \\cellcolor{yellow}{27.6125} & \\cellcolor{yellow}{27.6125} & \\cellcolor{yellow}{27.6125}\\\\\n\\hline\n\\cellcolor{yellow}{SS Flow} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{SS Flow} & \\cellcolor{yellow}{110.45} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\nNow we treat each no-Flow score as the mean for the no-Flow condition (6.6), and subtract it from the grand mean (8.95), to get -2.35. Then, we treat each Flow score as the mean for the Flow condition (11.3), and subtract it from the grand mean (8.95), to get +2.35. Then we square the differences and sum them up.\n\n### SS Pollution by Flow\n\nWe need to compute the SS for the interaction effect between Pollution and Flow. This is the new thing that we do in an ANOVA with more than one IV. How do we calculate the variation explained by the interaction?\n\nThe heart of the question is something like this. Do the individual means for each of the four conditions do something a little bit different than the group means for both of the independent variables? \n\nFor example, consider the overall mean for all of the scores in the Low Flow group, we found that to be 6.6 Now, was the mean for each no-Flow group in the whole design a 6.6? For example, in the no-Pollution group, was the mean for column A (the no-Flow condition in that group) also 6.6? The answer is no, it was 9.6. How about the Pollution group? Was the mean for the Flow condition in the Pollution group (column B) 6.6? No, it was 3.6. The mean of 9.6 and 3.6 is 6.6. If there was no hint of an interaction, we would expect that the means for the Flow condition in both levels of the Pollution group would be the same, they would both be 6.6. However, when there is an interaction, the means for the Flow group will depend on the levels of the group from another IV. In this case, it looks like there is an interaction because the means are different from 6.6, they are 9.6 and 3.6 for the no-Pollution and Pollution conditions. This is extra-variance that is not explained by the mean for the Flow condition. We want to capture this extra variance and sum it up. Then we will have measure of the portion of the variance that is due to the interaction between the Flow and Pollution conditions.\n\nWhat we will do is this. We will find the four condition means. Then we will see how much additional variation they explain beyond the group means for Flow and Pollution. To do this we treat each score as the condition mean for that score. Then we subtract the mean for the Pollution group, and the mean for the Flow group, and then we add the grand mean. This gives us the unique variation that is due to the interaction. We could also say that we are subtracting each condition mean from the grand mean, and then adding back in the Pollution mean and the Flow mean, that would amount to the same thing, and perhaps make more sense.\n\nHere is a formula to describe the process for each score:\n\n$\\bar{X}_\\text{condition} -\\bar{X}_\\text{IV1} - \\bar{X}_\\text{IV2} + \\bar{X}_\\text{Grand Mean}$\n\nOr we could write it this way:\n\n$\\bar{X}_\\text{condition} - \\bar{X}_\\text{Grand Mean} + \\bar{X}_\\text{IV1} + \\bar{X}_\\text{IV2}$\n\nWhen you look at the following table, we apply this formula to the calculation of each of the differences scores. We then square the difference scores, and sum them up to get $SS_\\text{Interaction}$, which is reported in the bottom yellow row.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-24_a68c16fc78db1679959da1fcfc63329d'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{l|l|l|l|l|l|l|l|l|>{}l|>{}l|>{}l|>{}l}\n\\hline\n\\multicolumn{1}{c|}{ } & \\multicolumn{4}{c|}{All Conditions} & \\multicolumn{4}{c|}{Interaction Differences} & \\multicolumn{4}{c}{Squared Differences} \\\\\n\\cline{2-5} \\cline{6-9} \\cline{10-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c|}{High Flow} & \\multicolumn{2}{c|}{Low Flow} & \\multicolumn{2}{c}{High Flow} \\\\\n\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-9} \\cline{10-11} \\cline{12-13}\n\\multicolumn{1}{c|}{ } & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c|}{Pollution} & \\multicolumn{1}{c|}{No Pollution} & \\multicolumn{1}{c}{Pollution} \\\\\n\\cline{2-2} \\cline{3-3} \\cline{4-4} \\cline{5-5} \\cline{6-6} \\cline{7-7} \\cline{8-8} \\cline{9-9} \\cline{10-10} \\cline{11-11} \\cline{12-12} \\cline{13-13}\n  & A & B & C & D & A-ND-NR+GM & B-D-NR+GM & C-ND-R+GM & D-D-R+GM & (A-ND-NR+GM)\\textasciicircum{}2 A & (B-D-NR+GM)\\textasciicircum{}2 B & (C-ND-R+GM)\\textasciicircum{}2 C & (D-D-R+GM)\\textasciicircum{}2 D\\\\\n\\hline\n & 10 & 5 & 12 & 9 & 0.85 & -0.85 & -0.85 & 0.85 & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225}\\\\\n\\hline\n & 8 & 4 & 13 & 8 & 0.85 & -0.85 & -0.85 & 0.85 & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225}\\\\\n\\hline\n & 11 & 3 & 14 & 10 & 0.85 & -0.85 & -0.85 & 0.85 & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225}\\\\\n\\hline\n & 9 & 4 & 11 & 11 & 0.85 & -0.85 & -0.85 & 0.85 & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225}\\\\\n\\hline\n & 10 & 2 & 13 & 12 & 0.85 & -0.85 & -0.85 & 0.85 & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225} & \\cellcolor{yellow}{0.7225}\\\\\n\\hline\n\\cellcolor{lightgray}{Means} & \\cellcolor{lightgray}{9.6} & \\cellcolor{lightgray}{3.6} & \\cellcolor{lightgray}{12.6} & \\cellcolor{lightgray}{10} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{lightgray}{Grand Mean} & \\cellcolor{lightgray}{8.95} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{lightgray}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\cellcolor{yellow}{sums} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{Sums} & \\cellcolor{yellow}{3.6125} & \\cellcolor{yellow}{3.6125} & \\cellcolor{yellow}{3.6125} & \\cellcolor{yellow}{3.6125}\\\\\n\\hline\n\\cellcolor{yellow}{SS Interaction} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{SS Interaction} & \\cellcolor{yellow}{14.45} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{} & \\cellcolor{yellow}{}\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n\n### SS Error\n\nThe last thing we need to find is the SS Error. We can solve for that because we found everything else in this formula:\n\n$SS_\\text{Total} = SS_\\text{Effect IV1} + SS_\\text{Effect IV2} + SS_\\text{Effect IV1xIV2} + SS_\\text{Error}$\n\nEven though this textbook meant to explain things in a step by step way, we guess you are tired from watching us work out the 2x2 ANOVA by hand. You and me both, making these tables was a lot of work. We have already shown you how to compute the SS for error before, so we will not do the full example here. Instead, we solve for SS Error using the numbers we have already obtained.\n\n\\$SS\\_\\text{Error} = SS\\_\\text{Total}- SS\\_\\text{Effect IV1} - SS\\_\\text{Effect IV2} - SS\\_\\text{Effect IV1xIV2} \\$\n\n\\$SS\\_\\text{Error} = 242.95 - 92.45 - 110.45 - 14.45 = 25.6 \\$\n\n### Check your work\n\nWe are going to skip the part where we divide the SSes by their dfs to find the MSEs so that we can compute the three $F$-values. Instead, if we have done the calculations of the $SS$es correctly, they should be same as what we would get if we used R to calculate the $SS$es. Let's make R do the work, and then compare to check our work.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-25_a3c0e4a6766c38404cb2d55319982b95'}\n::: {.cell-output-display}\n\\begin{tabular}{l|r|r|r|r|r}\n\\hline\n  & Df & Sum Sq & Mean Sq & F value & Pr(>F)\\\\\n\\hline\nPollution & 1 & 92.45 & 92.45 & 57.78125 & 0.0000011\\\\\n\\hline\nFlow & 1 & 110.45 & 110.45 & 69.03125 & 0.0000003\\\\\n\\hline\nPollution:Flow & 1 & 14.45 & 14.45 & 9.03125 & 0.0083879\\\\\n\\hline\nResiduals & 16 & 25.60 & 1.60 & NA & NA\\\\\n\\hline\n\\end{tabular}\n:::\n:::\n\n\n\nA quick look through the column `Sum Sq` shows that we did our work by hand correctly. Congratulations to us! Note, this is not the same results as we had before with the repeated measures ANOVA. We conducted a between-subjects design, so we did not get to further partition the SS error into a part due to subject variation and a left-over part. We also gained degrees of freedom in the error term. It turns out with this specific set of data, we find p-values of less than 0.05 for all effects (main effects and the interaction, which was not less than 0.05 using the same data, but treating it as a repeated-measures design)\n\n## Fireside chat\n\nSometimes it's good to get together around a fire and have a chat. Let's pretend we're sitting around a fire.\n\nIt's been a long day. A long couple of weeks and months since we started this course on statistics. We just went through the most complicated things we have done so far. This is a long chapter. What should we do next?\n\nHere's a couple of options. We could work through, by hand, more and more ANOVAs. Do you want to do that? I don't, making these tables isn't too bad, but it takes a lot of time. It's really good to see everything that we do laid bare in the table form a few times. We've done that already. It's really good for you to attempt to calculate an ANOVA by hand at least once in your life. It builds character. It helps you know that you know what you are doing, and what the ANOVA is doing. We can't make you do this, we can only make the suggestion. If we keep doing these by hand, it is not good for us, and it is not you doing them by hand. So, what are the other options.\n\nThe other options are to work at a slightly higher level. We will discuss some research designs, and the ANOVAs that are appropriate for their analysis. We will conduct the ANOVAs using R, and print out the ANOVA tables. This is what you do in the lab, and what most researchers do. They use software most of the time to make the computer do the work. Because of this, it is most important that you know what the software is doing. You can make mistakes when telling software what to do, so you need to be able to check the software's work so you know when the software is giving you wrong answers. All of these skills are built up over time through the process of analyzing different data sets. So, for the remainder of our discussion on ANOVAs we stick to that higher level. No more monster tables of SSes. You are welcome.\n\n## Real Data\n\nLet's go through the process of looking at a 2x2 factorial design in the wild. This will be the very same data that you will analyze in the lab for factorial designs.\n\n### Stand at attention\n\nConsider an example where a researcher is testing the effects of metal contamination on the number of species found in sessile marine invertebrates (sponges, bryozoans and sea squirts etc.). They would like to know whether copper reduces species richness, but also know that the richness of invertebrates can depend on whether the substrate is vertical or horizontal. Consequently, they ran an experiment where species richness was recorded in replicate samples in each of the six combinations of copper enrichment (\"None\",\"Low\",\"High\") and orientation (\"Vertical\",\"Horizontal\"). \n\nThe experimental design in termed factorial because all levels of one treatment are represented in all levels of the other treatment (also termed orthogonal). The general question and design is very similar to our fake study idea that we used to explain factorial designs in this chapter.\n\nThe paper we look at is called \"Stand by your Stroop: Standing up enhances selective attention and cognitive control\" [@rosenbaum2017stand]. This paper asked whether sitting versus standing would influence a measure of selective attention, the ability to ignore distracting information.\n\nThe factorial ANOVA will test:  \n* whether there are any differences in richness among the three levels of copper enrichment  \n* whether there are any differences in richness among the two levels of substrate orientation  \n* whether there is any interaction between copper and orientation\n\nYou have three null hypotheses:  \n* there is no difference between the means for each level of copper, H~o~: $\\mu_{None} = \\mu_{Low} = \\mu_{High}$  \n* there is no difference between the means for each level of orientation, $H~o~: $\\mu_{Vertical} = \\mu_{Horizontal}$  \n* there is no interaction between the factors\n\nThis is far better than running two separate single factor ANOVAs that contrast copper effects for each level of orientation because you have more statistical power (higher degrees of freedom) for the tests of interest, and you get a formal test of the interaction between factors which is often scientifically interesting.\n\nNote that an ANOVA is a linear model, just like linear regression except that the predictor variables are categorical rather than continuous. With two predictor variables, the linear model is:\n\n$$y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\varepsilon_{ijk}$$\n\nwhere $\\mu$ is the overall mean, $\\alpha_i$ is the effect of the i^th^ group of the first factor, and $\\beta_i$ is the effect of the j^th^ group of the second factor and $(\\alpha\\beta)$ is the interaction.\n\nAthough we have two factors, and an interaction effect, this requires fitting more than 3 parameters in our model because we have 3 levels of Factor A (Copper) and 2 levels of Factor B (Orientation) (if you can figure out how many parameters must be fit in this model, you are officially a stats geek! This is tricky even for those 'in the know').\n\nWith two factors, ANOVA partitions the total variance into a component that can be explained by the first predictor variable (among levels of the treatment A), a component that can be explained by the second predictor variable (among levels of the treatment B), a component that can be explained by the interaction, and a component that cannot be explained (within levels, the residual variance). The test statistic, *F*, is calculated three times to test each of the null hypotheses. For two fixed factors, the *F* ratios are:\n\n$$F = \\frac{MS_{A}}{MS_{within}}$$\n$$F = \\frac{MS_{B}}{MS_{within}}$$\n$$F = \\frac{MS_{AB}}{MS_{within}}$$\n\nwhere *MS* are the mean squares, a measure of variation. The probability of obtaining the observed value of *F* is calculated from the known probability distribution of *F*, with two degrees of freedom (one for the numerator = the number of levels -1) and one for the denominator. Note that these *F* ratios will change if any factors are random (see below for the distinction between fixed and random factors),\n  \n### Running the analysis\n \nYour data should be formatted with the measurements from each replicate as a row and each of the variables as columns, corresponding to the dependent variable *y*, Factor A and Factor B.\n\nWe'll download a sample data set for sessile invertebrates and import into R to to see the desired format. Check that your predictor variables are factors with the function `str`\n\n\n\n::: {.cell hash='cache/unnamed-chunk-26_d9a45ee15e59d84b1e73dda8c32ba771'}\n\n:::\n\n\n\nWith our predictor variable correctly assigned as factors, we can now run the analysis. As with other forms of linear models we have a model formula with the dependent variable, *y*, to the left of the ~ and the predictor variables to the right. For this two factor design, we use:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-27_1e20c965d4e8f5d7103a2253c0d290da'}\n\n:::\n\n\n\nNote that when you specify a model with * between the two predictors, R automatically includes both variables and their interaction. This same model could also be written as:\n\n\n\n::: {.cell hash='cache/unnamed-chunk-28_7dce6bdd6ba03b0e2b5fc264581c4e92'}\n\n:::\n\n\n\nThe output from this analysis can be seen by using the `summary` function on the object created.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-29_6609170a5383a26968936d323db7232f'}\n\n:::\n\n\n\n\nExactly the same model can also be run using the linear model function, `lm`.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-30_2bf23464e586e0e8dfae7df9dd8b950e'}\n\n:::\n\n\n  \n\n### Interpreting the results\n \n\n\n::: {.cell hash='cache/unnamed-chunk-31_b95aa092de6be694d38b5fbe68deb946'}\n\n```\n#>                    Df Sum Sq Mean Sq F value   Pr(>F)    \n#> Copper              2   3330  1665.0  192.53  < 2e-16 ***\n#> Orientation         1    240   240.0   27.75 2.46e-06 ***\n#> Copper:Orientation  2    571   285.4   33.00 4.34e-10 ***\n#> Residuals          54    467     8.6                     \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\nThe summary output of an ANOVA object is a table with the degrees of freedom (Df), sums of squares (Sum Sq), mean squares (Mean Sq) for the each of predictor variable (i.e., variation among levels of your treatments), their interaction and for the Residuals (i.e., varation within the levels). The test statistic, *F* value and its associated *p*-value (Pr(>F)) are also presented.\n\nCheck that you have the correct degrees of freedom. For a two factor design with fixed factors they are:   \n* Factor A: *a* - 1 (where *a* = number of levels of Factor A)  \n* Factor B: *b* - 1 (where *b* = number of levels of Factor B)  \n* Interaction (AB): (*a*-1)(*b*-1)  \n* Residual: *ab*(*n* -1) (where *n* = sample size)\n\nThe sums of squares and mean squares are measures of variation. There are three *F* statistics, corresponding to a test of each of the main effects and one for the interaction. The *p*-values are the probabilities of the observed *F* values from the *F* distribution (with the given degrees of freedom). \n\nIn this example, there is strong evidence to reject all three null hypotheses:  \n* that all levels of the copper treatment are equal (P < 0.001),  \n* that the vertical and horizontal orientations are equal (P < 0.001)  \n* that there is no interaction between copper and orientation (P < 0.001)\n\nA significant interaction means that the effect of one factor depends upon the other. In this example, it would mean that the effect of copper was not consistent between the vertical and horizontal habitats. Consequently, the interpretation of the main effects becomes more complex. See [Understanding interactions](/statistics/linear-models/interactions/) for more help on interpreting interactions in linear models. A quick way to help you understand an interaction if you get one is to examine an interactions plot.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-32_8321efef3fd737d62443663a0d2ef68f'}\n::: {.cell-output-display}\n![](10-FactorialANOVA_files/figure-pdf/unnamed-chunk-32-1.pdf){width=75%}\n:::\n:::\n\n\n\nHere you can see that the effect of copper (a decline in species richness) is more pronounced in the habitats with a vertical orientation, and that the difference between the two habitats changes with exposure to copper.\n \n\n**Multiple comparisons.** If you detect any significant differences in the ANOVA, we are then interested in knowing exactly which levels differ from one another, and which do not. Remember that a significant *p* value in the test you just ran would reject the null hypothesis the means were the same across all groups, but not identify which were different from each other. If there is no interaction, you can run a *post-hoc* test on each of the main effects (only needed if there are more than two levels for an effect). If there is an interaction, you will need to consider *post-hoc* tests that contrast the means from all combinations of both factors.\n  \n\n### Assumptions to check\n \nThe assumptions of factorial ANOVA's are the same as for all linear models including the simpler one-way ANOVA's (see [ANOVA: single factor](/statistics/linear-models/anova/anova-single/)), being independence, normality and homogeneity of variances. We also need to consider two new issues: 1) whether your factors are fixed or random, and 2) whether your sampling or experimental design is balanced (i.e., has the same number of replicates in each combination of treatments).\n\n**Fixed and random factors.** There is an important distinction between factors whose levels are the only ones of interest (termed fixed), and factors whose levels are a sampled from a larger collection of possible levels (termed random). For example, if we repeated the experiment above at three different sites in Sydney Harbour, chosen from many possible sites, we would consider site a random factor. We are not interested in those sites in particular, but would like to know if our experimental treatments were consistent across sites. On the other hand, if you were only interested in Darling Harbour and Circular Quay, then these two could be considered two levels of a fixed factor. Treating sites as a fixed factor in that case means that you conclusions should not be extrapolated to other possible sites, but restricted to those particular sites.\n\nStatistically, there is a big difference between a fixed factors were you have measured all possible levels of interest (e.g, control vs a single treatment) and random factors where the levels are sampled from all possible levels. In analysis of variance, all this matters because the *F* tests that are being used to test your hypotheses are constructed differently depending on which factors are fixed and random. In the example above, all factors were fixed and the denominator of all *F* tests was $MS_{within}$. In models with all factors random, and models with a mix of fixed and random factors (termed mixed effects models), other components of the variation are used as the denominators in the *F* tests.\n\nIf you have random factors, you will need to read more than this help page to establish the correct *F* ratios for your design, and you may need to calculate them manually. Note that the code presented will give correct *F* tests only for designs with all factors fixed. You should also strongly consider analysing your data as a [mixed model](/statistics/mixed-models/)\n\n**Balanced and unbalanced designs.** Ideally, factorial ANOVA should be conducted with a balanced design - one with  the same number of replicates in each combination of factors. Balanced designs are less likely to be affected by minor deviations from the assumptions of normality and homogeneity of variance. Unfortunately, unbalanced designs where you have unequal numbers of replicates for each level are common in practice (e.g. bad weather prevented sampling the second site as intensively, volunteer lost the data sheet etc!).\n\nUnbalanced designs are more susceptible to violating the assumptions of ANOVA and there is no single way to partitioning the $SS_{total}$ into the main effect and interaction components. The `aov` and `lm` functions in R use what are called Type I sums of squares where the terms in the model are fitted sequentially (i.e., how much variation is explained by factor A, then how much additional variation is explained by adding factor B). This means that the order of the terms in model matters: the model formulae `Y ~ A + B + A:B` and `Y ~ B + A + B:A` will give you different results.\n\nThere is a fair bit of debate on this in the statistical literature, but many advise using what are called Type II or Type III sums of squares for unbalanced designs. Other software packages like SPSS, SYSTAT and Minitab will automatically use Type III sums of squares where the order of terms in the model doesn't matter. To access these in R, we can use the `Anova` function in the [car](https://cran.r-project.org/web/packages/car/index.html) package.\n\n**Normality.** The assumption of normality can be checked by a frequency histogram of the residuals or by using a quantile plot where the residuals are plotted against the values expected from a normal distribution. The histogram of residuals should follow a normal distribution. If the points in the quantile plot lie mostly on the line, the residuals are normally distributed. Both of these plots can be obtained from the model object created by the `aov` function.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-33_cdcf4933888d73467afa1ddb103a70b4'}\n::: {.cell-output-display}\n![](10-FactorialANOVA_files/figure-pdf/unnamed-chunk-33-1.pdf){width=75%}\n:::\n:::\n\n\n\nViolations of normality can be fixed via transformations or by using a different error-distribution in a [generalised linear model (GLM)](/statistics/glms/).\n\n**Homogeneity of variance.** The assumption of homgeneity of variance, namely that the variation in the residuals is approximately equal across the range of the predictor variable, can be checked by plotting the residuals against the fitted values from the `aov` model object.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-34_a28cab0c82b812c9e5702c7d7d7f8b9c'}\n::: {.cell-output-display}\n![](10-FactorialANOVA_files/figure-pdf/unnamed-chunk-34-1.pdf){width=75%}\n:::\n:::\n\n\n\nHeterogeneous variances are indicated by non-random pattern in the residuals vs. fitted plot. Look for an even spread of the residuals on the y axis for each of the levels on the x axis. A fan-shaped distribution with more variance at higher values on the x axis is a common problem when data are skewed. See the testing assumptions of linear models module for more information. If there are strong patterns, one potential solution is to transform the response variable *y*. If this doesn't fix the problem the best solution is to use a different error distribution in a  [generalised linear model (GLM)](/statistics/glms/).\n\n**Independence.** ANOVA assumes that all replicate measures are independent of each other (i.e., equally likely to be sampled from the population of possible values for each level). This issue needs to be considered at the design stage. If data are grouped in any way (e.g., half the invertebrate samples measured at one time, then the other half measured later), then more complex designs are needed to account for additional factors (e.g., a design with an additional factor of sampling time).\n\nThere are a variety of measures for dealing with non-independence. These include ensuring all important predictors are in the model; averaging across nested observations; or using a [mixed model](/statistics/mixed-models/)\n  \n\n### Communicating the results\n \n**Written.**  The results of the main effects and any interaction should be described in the text of a results section. Each *F* test can be described in the text, e.g., \"The copper treatment and substrate orientation interacted to affect the species of sessile invertebrates (*F* = 19.33, df = 2,54, *p* < 0.001)\". Alternatively, all tests could be put into a Table like the one given in the output following `summary(Sessile.aov)` above. Description of the main tests would be followed by a description of the *post-hoc* results if used.\n\nRemember that the interpretation of the main effects is complicated when there is a significant interaction (see above). In this example, while copper reduced species richness, that effect was not consistent between the two habitats. In other scenarios with an interaction, you might have copper affecting richness in one habitat but not another, preventing you making a simple statement like \"copper reduced species richness\" because it wouldn't always be true. \n\n**Visual.** A boxplot or column graph with error bars are suitable for contrasting a continuous variable across levels of categorical variable. See the graphing modules for making publication ready versions of these figures.\n\n\n\n::: {.cell hash='cache/unnamed-chunk-35_1c0621b4acba028760b46f496e563b2e'}\n::: {.cell-output-display}\n![](10-FactorialANOVA_files/figure-pdf/unnamed-chunk-35-1.pdf){width=75%}\n:::\n:::\n\n\n  \n\n## Factorial summary\n\nWe have introduced you to factorial designs, which are simply designs with more than one IV. The special property of factorial designs is that all of the levels of each IV need to be crossed with the other IVs.\n\nWe showed you how to analyse a repeated measures 2x2 design with paired samples-tests, and what an ANOVA table would look like if you did this in R. We also went through, by hand, the task of calculating an ANOVA table for a 2x2 between subjects design.\n\nThe main point we want you take away is that factorial designs are extremely useful for determining things that cause effects to change. Generally a researcher measures an effect of interest (their IV 1). Then, they want to know what makes that effect get bigger or smaller. They want to exert experimental control over their effect. For example, they might have a theory that says doing X should make the effect bigger, but doing Y should make it smaller. They can test these theories using factorial designs, and manipulating X or Y as a second independent variable.\n\nIn a factorial design each IV will have it's own main effect. Sometimes the main effect themselves are what the researcher is interested in measures. But more often, it is the interaction effect that is most relevant. The interaction can test whether the effect of IV1 changes between the levels of IV2. When it does, researchers can infer that their second manipulation (IV2) causes change in their effect of interest. These changes are then documented and used to test underlying causal theories about the effects of interest.\n\n",
    "supporting": [
      "10-FactorialANOVA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}