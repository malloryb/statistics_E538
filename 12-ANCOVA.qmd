---
author: 
  - Mallory L. Barnes
aliases: [simulating-data.html]
---

```{r, include = FALSE}
source("global_stuff.R")
```

# ANCOVA

```{r}
library(ggplot2)
library(dplyr)
```

## General Linear Models (GLM)

In our journey through statistical modeling, we've encountered three primary parametric models, each suited for different types of data scenarios:

-   **No Groups and No Relationships (H0):**
    -   This scenario often emerges when our ANOVA or regression analysis yields non-significant results.
    -   **What We Report:** The grand mean and overall variance or standard deviation. Alternatively, we can use a confidence interval to encapsulate this information.
-   **Two or More Categories with Significantly Different Means (t-test, ANOVA):**
    -   Here, we delve into data where group means are distinct and significant.
    -   **What We Report:** Group means. In classical ANOVA, we might report a common variance or standard deviation, or opt for group-specific measures (potentially through confidence intervals), ensuring to note that variances are not significantly different. With Welch's t-test, we focus on group-specific variance or standard deviation.
-   **Two Continuous Variables with a Significant Linear or Monotonic Relationship (Regression):**
    -   This model applies when there's a significant linear relationship between two continuous variables.
    -   **What We Report:** The equation of the regression line, along with its confidence limits. We can also select specific x-values and provide confidence intervals for the predicted y-values at those points.

### Model Statements:

-   **No Groups/Relationships:** `y∼N(μ,σ²)`
-   **Categories with Different Means:** `yᵢ,ⱼ = μ + τᵢ + ε` (t-test allows for unequal variance: `yᵢ,ⱼ = μ + τᵢ + εᵢ`)
-   **Linear Relationship:** `y = β₀ + β₁x + ε`

### Flexibility and Applicability of GLMs in Environmental Informatics

So far, in our exploration of parametric tests, we have primarily focused on two types of relationships:

-   **A categorical X and a continuous Y:** This includes tests like the t-test and ANOVA.
-   **A continuous X and a continuous Y:** This is typically analyzed using linear regression.

General Linear Models (GLMs) significantly expand our analytical capabilities in environmental informatics. They are not limited to just these basic scenarios but offer a more versatile toolkit. GLMs are particularly adept at handling:

-   **More Complex Relationships:** They can model scenarios where relationships between variables are not strictly linear.
-   **Diverse Data Types:** GLMs are suitable for various data types, including count data, which is often encountered in environmental studies.

This flexibility makes GLMs an invaluable tool in our field, allowing us to explore and understand the intricate dynamics of environmental systems more comprehensively.

## Moving Beyond Regression and ANOVA to GLM

Now, we integrate the concepts of ANOVA with regression. This integration allows us to explore x-y relationships across multiple categories. Our aim is to address questions about relationships in two distinct categories, such as:

-   **Are dbh (Diameter at Breast Height) and height related similarly for tulip poplars and oaks?**
-   **Are biomass and BTUs (British Thermal Units) related similarly for corn stover and Miscanthus?**
-   **Are age and proportion of income donated to charity similarly related for Democrats and Republicans?**

This specific subsection of general linear models is known as **Analysis of Covariance -- ANCOVA**.

### Understanding ANCOVA

With ANCOVA, if we identify a significant difference between two linear relationships, our model will represent two distinct lines. The challenge then becomes integrating these two lines into a single equation.

#### Conceptualizing the Transformation

Consider the following equations:

-   `y = 2x + 3`
-   `y = 3x - 4`

The question we pose is: What modifications are required to transform the first equation into the second? This involves determining the adjustments needed in terms of x (the slope) and the constant term. Understanding this transformation is key to grasping how ANCOVA allows us to compare different linear relationships within a single model framework.

## Introducing the Indicator or Dummy Variable

In General Linear Models (GLMs), the use of indicator or dummy variables is crucial. These variables allow us to include categorical variables in models traditionally designed for continuous variables.

### Understanding Indicator Variables

Indicator variables are used to encode categories. For `n` categories, you need `n-1` indicator variables.

#### Example with Wombat Species

Consider a scenario with 5 species of wombat. We can code these species using 4 indicator variables:

| Ind1 | Ind2 | Ind3 | Ind4 | Species   |
|------|------|------|------|-----------|
| 1    | 0    | 0    | 0    | Species 1 |
| 0    | 1    | 0    | 0    | Species 2 |
| 0    | 0    | 1    | 0    | Species 3 |
| 0    | 0    | 0    | 1    | Species 4 |
| 0    | 0    | 0    | 0    | Species 5 |

In the simplest case of two categories, only one indicator variable is needed:

-   0 = Wombat Species 1
-   1 = Wombat Species 2

### The Concept of "Turning On" an Indicator Variable

In the context of GLMs, "turning on" an indicator variable means assigning it a value of 1. This action activates certain terms in the equation that are multiplied by the indicator variable, thereby altering the model's output.

#### Impact on the Equation

When an indicator variable (`xc`) is set to 1, it effectively activates any terms in the equation that are multiplied by `xc`. This can change the slope and/or intercept of the regression line, depending on how `xc` is used in the equation.

For example, in the equation `y = 2xl + 3 + 1xcxl - 7xc`:

- When `xc` = 0 (turned off), the equation simplifies to `y = 2xl + 3`. Here, the terms `1xcxl` and `-7xc` are deactivated because they are multiplied by `xc`, which is 0.
- When `xc` = 1 (turned on), the equation becomes `y = (2xl + 3) + (1xl - 7)`. In this case, the terms `1xcxl` and `-7xc` are activated, altering the slope and intercept of the line.

#### Visualizing the Effect

The R plots below demonstrate the change in the regression line when the indicator variable is toggled between being active (`xc = 1`) and inactive (`xc = 0`).

**When `xc` = 0:**  
*Equation Simplified:* `y = 2xl + 3`  
This plot shows the regression line when the indicator variable is inactive. The equation simplifies, reflecting a scenario where the categorical variable does not influence the outcome.

```{r}
# Graph for when xc = 0
# Equation becomes: y = 2xl + 3

# Example data frame
data_xc0 <- data.frame(
  xl = c(1, 2, 3, 4, 5))
data_xc0$y= (2 * data_xc0$xl + 3) 

# Plot for xc = 0
ggplot(data_xc0, aes(x = xl, y = y)) +
  geom_line() +
  labs(title = "Regression Line when xc = 0",
       x = "Continuous Variable (xl)",
       y = "Dependent Variable (y)")+
  theme_classic()+
  ylim(-1,15)
```

**When `xc` = 1:**  
*Equation Modified:* `y = (2xl + 3) + (1xl - 7)`  
This plot illustrates the regression line when the indicator variable is active. The equation now includes additional terms, showcasing how the presence of the categorical variable changes the relationship between `xl` and `y`.

```{r}
# Graph for when xc = 1
# Equation becomes: y = (2xl + 3) + (1xl - 7)
data_xc1 <- data.frame(
  xl = c(1, 2, 3, 4, 5))

data_xc1$y <- ((2 * data_xc1$xl + 3) + (1 * data_xc1$xl - 7)) 


# Plot for xc = 1
ggplot(data_xc1, aes(x = xl, y = y)) +
  geom_line() +
  labs(title = "Regression Line when xc = 1",
       x = "Continuous Variable (xl)",
       y = "Dependent Variable (y)")+
  theme_classic()+
  ylim(-1,15)
```

Using indicator variables, we can create models in which regression lines change completely depending on which category we're modeling. If we need to tweak both the intercept and the slope, then we will need two new regression parameters -- β2 and β3 .

### Interaction Term in GLMs

If we only have β2 in our equation, we have an odd subset of the two-line case.

Consider this equation in β0, β1, and β2

y = 14.2 + 5.2xl + 3.9xc β0 β1 β2

What equation is operating when the categorical variable (xc) = 0?

What equation is operating when the categorical variable (xc) = 1?

Graph these on the axes below:

```         
                               48   -      
                               44   -
                               42   -
                               38   -
                               34   -
                               30   -
                               26   -
                               22   -
                               18   - 
                               14   -

                                          0                 1                 2
```

What is the effect of "turning on" β2 ?

Now, consider the more usual case, when we need all four parameters, β0, β1, β2, and β3

y = 14.2 + 5.2xl + 3.9xc + 0.2xlx¬c β0 β1 β2 β3

What equation is operating when the categorical variable (xc) = 0?

What equation is operating when the categorical variable (xc) = 1?

Graph these on the axes below:

```         
                               52   -  
                               48   -      
                               44   -
                               42   -
                               38   -
                               34   -
                               30   -
                               26   -
                               22   -
                               18   - 
                               14   -

                                          0                 1                 2
```

What is the effect of "turning on" β2 and β3?

  β3 is called an interaction term because when it is significant, it tells us that the continuous and categorical variables interact, so that the effect of the continuous variable is different for the different categories.

y = β0 + β1xl + β2xc + β3xlxc + ε `β3` is known as an interaction term. It's significant when the continuous and categorical variables interact, meaning the effect of the continuous variable differs across categories.

`y = β0 + β1xl + β2xc + β3xlxc + ε`

### Terminology in GLMs

-   **Fixed Factor:** If the categorical X variable represents specific values of interest (e.g., season, harvest strategy, political party), it's a fixed factor.
-   **Random Factor:** If the categorical X variable represents random values from a broader range (e.g., output from randomly chosen machines), it's a random factor.
-   **Covariate:** The continuous X variable, varying with Y.

### Understanding Interactions Through an Example

Seedling density varies with distance from the parent tree for both species -- the covariate is significant. The intercepts are different, so the categorical variable is likely to be significant. The slopes are different, meaning that the differences between the species are different at different values of the covariate X. This means the interaction term is significant. The differences are different. There is an interaction between the value of the covariate (distance) and the difference between the species (the categorical factor).

The mark of a significant interaction is that you do not have constant differences between categories or between points along the continuous variable.
